name: Reusable - Nightly E2E GKE (Helmfile)

# Reusable workflow for nightly e2e testing of helmfile-based llm-d guides
# on GKE. Called by the llm-d/llm-d repo to deploy a guide's stack
# via helmfile and run the e2e-validate.sh smoke-test suite.
#
# Usage from a caller workflow:
#
#   jobs:
#     nightly:
#       uses: llm-d/llm-d-infra/.github/workflows/reusable-nightly-e2e-gke-helmfile.yaml@main
#       with:
#         guide_name: inference-scheduling
#         namespace: llm-d-nightly-inference
#         helmfile_env: gke
#       secrets: inherit

on:
  workflow_call:
    inputs:
      # --- Guide configuration ---
      guide_name:
        description: 'Guide directory name under guides/ in llm-d/llm-d'
        required: true
        type: string
      guide_path:
        description: 'Override path to guide directory (default: guides/<guide_name>)'
        required: false
        type: string
        default: ''
      namespace:
        description: 'Kubernetes namespace for the deployment'
        required: true
        type: string
      helmfile_env:
        description: 'Helmfile environment (gke, gke_tpu, etc.)'
        required: false
        type: string
        default: 'gke'
      gateway_type:
        description: 'Gateway provider type (gke, istio, kgateway)'
        required: false
        type: string
        default: 'gke'

      # --- Repository ---
      llm_d_ref:
        description: 'Git ref for llm-d/llm-d checkout (default: main)'
        required: false
        type: string
        default: 'main'

      # --- GKE cluster configuration ---
      gcp_project_id:
        description: 'GCP project ID'
        required: false
        type: string
        default: 'llm-d-scale'
      gke_cluster_name:
        description: 'GKE cluster name'
        required: false
        type: string
        default: 'llm-d-e2e-us-east5'
      gke_cluster_zone:
        description: 'GKE cluster zone'
        required: false
        type: string
        default: 'us-east5'

      # --- GPU requirements ---
      required_gpus:
        description: 'Minimum GPUs required (0 for simulated)'
        required: false
        type: number
        default: 2
      recommended_gpus:
        description: 'Recommended GPUs for scale-up headroom'
        required: false
        type: number
        default: 4
      gpu_wait_timeout:
        description: 'Minutes to wait for GPUs to become available (0 = no wait, fail immediately)'
        required: false
        type: number
        default: 0
      allow_gpu_preemption:
        description: 'When true, proceed with deployment even if GPUs are unavailable (relies on Kubernetes preemption of lower-priority pods)'
        required: false
        type: boolean
        default: false

      # --- Model & accelerator ---
      model_id:
        description: 'Model ID (empty = auto-discover from guide)'
        required: false
        type: string
        default: ''
      accelerator_type:
        description: 'Accelerator type (H100, A100, L4, TPU)'
        required: false
        type: string
        default: 'L4'

      # --- Deployment configuration ---
      helmfile_args:
        description: 'Extra args passed to helmfile apply (e.g. --set key=val)'
        required: false
        type: string
        default: ''
      httproute_file:
        description: 'HTTPRoute file to apply (empty = skip)'
        required: false
        type: string
        default: 'httproute.gke.yaml'
      pre_deploy_script:
        description: 'Script to run before deployment (e.g. slim transforms)'
        required: false
        type: string
        default: ''
      custom_deploy_script:
        description: 'Custom deploy script — replaces helmfile apply (for kustomize/helm guides)'
        required: false
        type: string
        default: ''
      image_override:
        description: 'Override vLLM container image (e.g. ghcr.io/llm-d/llm-d-cuda-dev:latest)'
        required: false
        type: string
        default: ''

      # --- Test configuration ---
      e2e_validate_args:
        description: 'Extra args for e2e-validate.sh (e.g. -m model-id)'
        required: false
        type: string
        default: ''
      pod_wait_timeout:
        description: 'Timeout for pods to become ready'
        required: false
        type: string
        default: '30m'
      pod_readiness_delay:
        description: 'Extra delay after pods are ready (for model loading)'
        required: false
        type: number
        default: 180

      # --- Cleanup ---
      skip_cleanup:
        description: 'Skip cleanup after tests (for debugging)'
        required: false
        type: boolean
        default: false

jobs:
  nightly-e2e:
    runs-on: ubuntu-latest
    env:
      GUIDE_NAME: ${{ inputs.guide_name }}
      GUIDE_PATH: ${{ inputs.guide_path || format('guides/{0}', inputs.guide_name) }}
      NAMESPACE: ${{ inputs.namespace }}
      HELMFILE_ENV: ${{ inputs.helmfile_env }}
      GATEWAY_TYPE: ${{ inputs.gateway_type }}
      ACCELERATOR_TYPE: ${{ inputs.accelerator_type }}
      GCP_PROJECT_ID: ${{ inputs.gcp_project_id }}
      GKE_CLUSTER_NAME: ${{ inputs.gke_cluster_name }}
      GKE_CLUSTER_ZONE: ${{ inputs.gke_cluster_zone }}
      HF_TOKEN: ${{ secrets.HF_TOKEN }}
    steps:
      - name: Checkout llm-d/llm-d
        uses: actions/checkout@v6
        with:
          repository: llm-d/llm-d
          ref: ${{ inputs.llm_d_ref }}
          persist-credentials: false

      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@b7593ed2efd1c1617e1b0254da33b86225adb2a5
        with:
          credentials_json: ${{ secrets.GKE_SA_KEY }}

      - name: Set up gcloud CLI and kubectl
        uses: google-github-actions/setup-gcloud@aa5489c8933f4cc7a4f7d45035b3b1440c9c10db
        with:
          project_id: ${{ env.GCP_PROJECT_ID }}
          install_components: 'kubectl,gke-gcloud-auth-plugin'

      - name: Get GKE credentials
        run: |
          gcloud container clusters get-credentials "$GKE_CLUSTER_NAME" \
            --zone "$GKE_CLUSTER_ZONE" \
            --project "$GCP_PROJECT_ID"

      - name: Install prerequisites (helm, helmfile, yq)
        run: |
          # Install standard llm-d prerequisites (kubectl, helm, helmfile, yq)
          ./guides/prereq/client-setup/install-deps.sh

          # Install jq if not present
          if ! command -v jq &>/dev/null; then
            sudo apt-get update && sudo apt-get install -y jq
          fi

      - name: Verify cluster access
        run: |
          echo "Verifying GKE cluster access..."
          kubectl cluster-info
          kubectl get nodes

      - name: Cordon unhealthy GPU nodes
        run: |
          echo "Checking for unhealthy GPU nodes to cordon..."
          CORDONED_NODES=""
          for node in $(kubectl get nodes -o json | jq -r '
            .items[] | select(
              ((.status.allocatable["nvidia.com/gpu"] // "0" | tonumber) > 0) and
              (.status.conditions[] | select(.type == "Ready") | .status != "True")
            ) | .metadata.name'); do
            echo "::warning::Cordoning unhealthy GPU node: $node"
            kubectl cordon "$node" 2>/dev/null || true
            CORDONED_NODES="$CORDONED_NODES $node"
          done
          echo "NIGHTLY_CORDONED_NODES=$CORDONED_NODES" >> $GITHUB_ENV
          if [ -z "$CORDONED_NODES" ]; then
            echo "All GPU nodes are healthy"
          else
            echo "Cordoned nodes:$CORDONED_NODES"
          fi

      - name: Check GPU availability
        id: gpu-check
        env:
          REQUIRED_GPUS: ${{ inputs.required_gpus }}
          RECOMMENDED_GPUS: ${{ inputs.recommended_gpus }}
          GPU_WAIT_TIMEOUT: ${{ inputs.gpu_wait_timeout }}
        run: |
          echo "Checking GPU availability for nightly e2e ($GUIDE_NAME)..."

          check_gpus() {
            TOTAL_GPUS=$(kubectl get nodes -o json | \
              jq '[.items[].status.allocatable["nvidia.com/gpu"] // "0" | tonumber] | add // 0')
            ALLOCATED_GPUS=$(kubectl get pods --all-namespaces -o json | \
              jq '[.items[] | select(.status.phase == "Running" or .status.phase == "Pending") | .spec.containers[]?.resources.requests["nvidia.com/gpu"] // "0" | tonumber] | add // 0')
            AVAILABLE_GPUS=$((TOTAL_GPUS - ALLOCATED_GPUS))
          }

          check_gpus

          NODE_COUNT=$(kubectl get nodes --no-headers | wc -l | tr -d ' ')
          GPU_NODE_COUNT=$(kubectl get nodes -o json | \
            jq '[.items[] | select((.status.allocatable["nvidia.com/gpu"] // "0" | tonumber) > 0)] | length')

          echo "total_gpus=$TOTAL_GPUS" >> $GITHUB_OUTPUT
          echo "allocated_gpus=$ALLOCATED_GPUS" >> $GITHUB_OUTPUT
          echo "available_gpus=$AVAILABLE_GPUS" >> $GITHUB_OUTPUT

          echo "## GPU Status — Nightly ($GUIDE_NAME on GKE)" >> $GITHUB_STEP_SUMMARY
          echo "| Metric | Count |" >> $GITHUB_STEP_SUMMARY
          echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
          echo "| Cluster | $GKE_CLUSTER_NAME ($GKE_CLUSTER_ZONE) |" >> $GITHUB_STEP_SUMMARY
          echo "| Total cluster GPUs | $TOTAL_GPUS |" >> $GITHUB_STEP_SUMMARY
          echo "| Currently allocated | $ALLOCATED_GPUS |" >> $GITHUB_STEP_SUMMARY
          echo "| Available | $AVAILABLE_GPUS |" >> $GITHUB_STEP_SUMMARY
          echo "| Required (minimum) | $REQUIRED_GPUS |" >> $GITHUB_STEP_SUMMARY
          echo "| Recommended (with scale-up) | $RECOMMENDED_GPUS |" >> $GITHUB_STEP_SUMMARY
          echo "| Nodes | $NODE_COUNT ($GPU_NODE_COUNT with GPUs) |" >> $GITHUB_STEP_SUMMARY

          if [ "$REQUIRED_GPUS" -eq 0 ]; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "**No GPUs required** for this guide (simulated accelerators)" >> $GITHUB_STEP_SUMMARY
          elif [ "$AVAILABLE_GPUS" -lt "$REQUIRED_GPUS" ]; then
            if [ "${GPU_WAIT_TIMEOUT:-0}" -gt 0 ]; then
              DEADLINE=$((SECONDS + GPU_WAIT_TIMEOUT * 60))
              echo "::notice::Waiting up to ${GPU_WAIT_TIMEOUT}m for GPUs (need $REQUIRED_GPUS, have $AVAILABLE_GPUS)..."
              while [ $SECONDS -lt $DEADLINE ]; do
                REMAINING=$(( (DEADLINE - SECONDS) / 60 ))
                echo "[$(date +%H:%M:%S)] Waiting for GPUs... need $REQUIRED_GPUS, have $AVAILABLE_GPUS (${REMAINING}m remaining)"
                sleep 120
                check_gpus
                if [ "$AVAILABLE_GPUS" -ge "$REQUIRED_GPUS" ]; then
                  echo "[$(date +%H:%M:%S)] GPUs now available: $AVAILABLE_GPUS free"
                  echo "available_gpus=$AVAILABLE_GPUS" >> $GITHUB_OUTPUT
                  echo "allocated_gpus=$ALLOCATED_GPUS" >> $GITHUB_OUTPUT
                  break
                fi
              done
            fi
            # If still insufficient after waiting, try preemption or fail
            if [ "$AVAILABLE_GPUS" -lt "$REQUIRED_GPUS" ]; then
              if [ "${{ inputs.allow_gpu_preemption }}" = "true" ]; then
                # Count GPU pods with default priority (0) or negative — these can be
                # preempted by nightly pods deployed with a higher PriorityClass.
                PREEMPTABLE_GPU_COUNT=$(kubectl get pods --all-namespaces -o json | \
                  jq '[.items[] | select(
                    (.spec.containers[]?.resources.limits["nvidia.com/gpu"] // "0" | tonumber) > 0
                    and (.spec.priority // 0) <= 0
                  ) | .spec.containers[]?.resources.limits["nvidia.com/gpu"] // "0" | tonumber] | add // 0')
                PREEMPTABLE_POD_COUNT=$(kubectl get pods --all-namespaces -o json | \
                  jq '[.items[] | select(
                    (.spec.containers[]?.resources.limits["nvidia.com/gpu"] // "0" | tonumber) > 0
                    and (.spec.priority // 0) <= 0
                  )] | length')
                POTENTIAL_GPUS=$((AVAILABLE_GPUS + PREEMPTABLE_GPU_COUNT))
                if [ "$POTENTIAL_GPUS" -ge "$REQUIRED_GPUS" ]; then
                  echo "" >> $GITHUB_STEP_SUMMARY
                  echo "**Insufficient free GPUs** — need $REQUIRED_GPUS but only $AVAILABLE_GPUS free. Found $PREEMPTABLE_POD_COUNT preemptable GPU pod(s) holding $PREEMPTABLE_GPU_COUNT GPU(s) — proceeding (Kubernetes will preempt as needed)." >> $GITHUB_STEP_SUMMARY
                  echo "::warning::Insufficient free GPUs ($AVAILABLE_GPUS/$REQUIRED_GPUS) but $PREEMPTABLE_GPU_COUNT preemptable GPUs available (priority <= 0)"
                else
                  WAIT_MSG=""
                  [ "${GPU_WAIT_TIMEOUT:-0}" -gt 0 ] && WAIT_MSG=" (after waiting ${GPU_WAIT_TIMEOUT}m)"
                  echo "" >> $GITHUB_STEP_SUMMARY
                  echo "**Insufficient GPUs${WAIT_MSG}** — need $REQUIRED_GPUS, have $AVAILABLE_GPUS free + $PREEMPTABLE_GPU_COUNT preemptable = $POTENTIAL_GPUS total (not enough)." >> $GITHUB_STEP_SUMMARY
                  echo "::error::Insufficient GPUs: need $REQUIRED_GPUS, have $AVAILABLE_GPUS free + $PREEMPTABLE_GPU_COUNT preemptable = $POTENTIAL_GPUS total.${WAIT_MSG}"
                  exit 1
                fi
              else
                WAIT_MSG=""
                [ "${GPU_WAIT_TIMEOUT:-0}" -gt 0 ] && WAIT_MSG=" (after waiting ${GPU_WAIT_TIMEOUT}m)"
                echo "" >> $GITHUB_STEP_SUMMARY
                echo "**Insufficient GPUs${WAIT_MSG}** — need $REQUIRED_GPUS but only $AVAILABLE_GPUS available." >> $GITHUB_STEP_SUMMARY
                echo "::error::Insufficient GPUs: need $REQUIRED_GPUS, have $AVAILABLE_GPUS available${WAIT_MSG}"
                exit 1
              fi
            else
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "**GPUs available after waiting** — $AVAILABLE_GPUS GPUs free ($REQUIRED_GPUS required, $RECOMMENDED_GPUS recommended)" >> $GITHUB_STEP_SUMMARY
            fi
          elif [ "$AVAILABLE_GPUS" -lt "$RECOMMENDED_GPUS" ]; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "**Low GPU headroom** — $AVAILABLE_GPUS available (need $RECOMMENDED_GPUS for scale-up tests)." >> $GITHUB_STEP_SUMMARY
            echo "::warning::Low GPU headroom: $AVAILABLE_GPUS available, $RECOMMENDED_GPUS recommended"
          else
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "**GPUs available** — $AVAILABLE_GPUS GPUs free ($REQUIRED_GPUS required, $RECOMMENDED_GPUS recommended)" >> $GITHUB_STEP_SUMMARY
          fi

      - name: Create nightly PriorityClass
        if: inputs.allow_gpu_preemption && inputs.required_gpus > 0
        run: |
          echo "Creating nightly-gpu-critical PriorityClass for GPU preemption..."
          cat <<'PRIORITY_EOF' | kubectl apply -f -
          apiVersion: scheduling.k8s.io/v1
          kind: PriorityClass
          metadata:
            name: nightly-gpu-critical
          value: 1000000
          preemptionPolicy: PreemptLowerPriority
          globalDefault: false
          description: "High priority for nightly E2E GPU workloads — preempts default-priority pods"
          PRIORITY_EOF

      - name: Clean up previous nightly resources
        run: |
          echo "Cleaning up previous nightly resources for $GUIDE_NAME..."
          echo "  NAMESPACE: $NAMESPACE"

          if kubectl get namespace "$NAMESPACE" &>/dev/null; then
            echo "=== Cleaning up namespace: $NAMESPACE ==="

            # Destroy helmfile releases if helmfile.yaml.gotmpl exists
            if [ -f "$GUIDE_PATH/helmfile.yaml.gotmpl" ]; then
              echo "  Destroying helmfile releases..."
              cd "$GUIDE_PATH"
              helmfile destroy -e "$HELMFILE_ENV" --namespace "$NAMESPACE" --args --ignore-not-found 2>/dev/null || true
              cd "$GITHUB_WORKSPACE"
            fi

            # Fallback: uninstall any remaining helm releases
            for release in $(helm list -n "$NAMESPACE" -q 2>/dev/null); do
              echo "  Uninstalling helm release: $release"
              helm uninstall "$release" -n "$NAMESPACE" --ignore-not-found --wait --timeout 60s || true
            done

            # Delete HTTPRoutes and other resources
            kubectl delete httproute --all -n "$NAMESPACE" --ignore-not-found || true
            kubectl delete gateway --all -n "$NAMESPACE" --ignore-not-found || true

            echo "  Deleting namespace: $NAMESPACE"
            kubectl delete namespace "$NAMESPACE" --ignore-not-found --timeout=120s || true
          else
            echo "Namespace $NAMESPACE does not exist, skipping"
          fi

          echo "Pre-cleanup complete"

      - name: Create namespace and HF token secret
        run: |
          echo "Creating namespace $NAMESPACE..."
          kubectl create namespace "$NAMESPACE" || echo "Namespace already exists"

          echo "Creating HF token secret in $NAMESPACE..."
          kubectl create secret generic llm-d-hf-token \
            --from-literal="HF_TOKEN=$HF_TOKEN" \
            --namespace "$NAMESPACE" \
            --dry-run=client -o yaml | kubectl apply -f -

      - name: Override vLLM image
        if: inputs.image_override != ''
        run: |
          set -euo pipefail
          echo "IMAGE_OVERRIDE=${{ inputs.image_override }}" >> $GITHUB_ENV
          echo "Overriding vLLM images to: ${{ inputs.image_override }}"
          VALUES_FILES=$(find "$GUIDE_PATH" -name "values*.yaml")
          if [ -z "$VALUES_FILES" ]; then
            echo "::warning::No values*.yaml files found in $GUIDE_PATH — image override will have no effect on values files"
          else
            for file in $VALUES_FILES; do
              echo "Updating vLLM image in ${file}..."
              # Guard each yq call: only modify if the key exists, otherwise yq creates ghost empty arrays
              yq e '(select(.decode.containers != null) | .decode.containers[].image | select(test("^ghcr\.io/llm-d/llm-d-cuda"))) = strenv(IMAGE_OVERRIDE)' -i "$file"
              yq e '(select(.prefill.containers != null) | .prefill.containers[].image | select(test("^ghcr\.io/llm-d/llm-d-cuda"))) = strenv(IMAGE_OVERRIDE)' -i "$file"
              yq e '(select(.containers != null) | .containers[].image | select(test("^ghcr\.io/llm-d/llm-d-cuda"))) = strenv(IMAGE_OVERRIDE)' -i "$file"
            done
          fi
        env:
          IMAGE_OVERRIDE: ${{ inputs.image_override }}

      - name: Run pre-deploy script
        if: inputs.pre_deploy_script != ''
        run: |
          echo "Running pre-deploy script..."
          ${{ inputs.pre_deploy_script }}

      - name: Deploy guide via helmfile
        if: inputs.custom_deploy_script == ''
        run: |
          echo "Deploying $GUIDE_NAME via helmfile (env: $HELMFILE_ENV)..."
          cd "$GUIDE_PATH"
          helmfile apply -e "$HELMFILE_ENV" \
            --namespace "$NAMESPACE" \
            --set "gateway.service.type=LoadBalancer" \
            --skip-schema-validation \
            ${{ inputs.helmfile_args }} \
            | tee /tmp/helmfile-deploy.log
          cd "$GITHUB_WORKSPACE"

      - name: Deploy guide via custom script
        if: inputs.custom_deploy_script != ''
        run: |
          echo "Deploying $GUIDE_NAME via custom script..."
          ${{ inputs.custom_deploy_script }}

      - name: Deploy HTTPRoute
        if: inputs.httproute_file != '' && inputs.custom_deploy_script == ''
        run: |
          HTTPROUTE="${GUIDE_PATH}/${{ inputs.httproute_file }}"
          if [ -f "$HTTPROUTE" ]; then
            echo "Deploying HTTPRoute from $HTTPROUTE..."
            kubectl apply -f "$HTTPROUTE" -n "$NAMESPACE"
          else
            echo "::warning::HTTPRoute file $HTTPROUTE not found — skipping"
          fi

      - name: Upload helm values
        if: inputs.custom_deploy_script == ''
        run: |
          for release in $(helm list -n "$NAMESPACE" -q 2>/dev/null); do
            bash .github/scripts/e2e/helm-get-all.sh \
              /tmp/helmfile-deploy.log \
              "$release" \
              "$NAMESPACE" || true
          done

      - name: Set nightly GPU priority on workloads
        if: inputs.allow_gpu_preemption && inputs.required_gpus > 0
        run: |
          echo "Setting priorityClassName=nightly-gpu-critical on GPU workloads in $NAMESPACE..."
          for kind in deployment statefulset; do
            for name in $(kubectl get "$kind" -n "$NAMESPACE" -o jsonpath='{.items[*].metadata.name}' 2>/dev/null); do
              # Check if this workload requests GPUs
              GPU_REQ=$(kubectl get "$kind" "$name" -n "$NAMESPACE" -o json | \
                jq '[.spec.template.spec.containers[]?.resources.limits["nvidia.com/gpu"] // "0" | tonumber] | add // 0')
              if [ "$GPU_REQ" -gt 0 ]; then
                echo "  Patching $kind/$name (requests $GPU_REQ GPU(s))..."
                if [ "$kind" = "deployment" ]; then
                  # Use Recreate strategy for GPU deployments to avoid rolling update deadlock.
                  # With RollingUpdate, new pods can't start because old pods hold the GPUs.
                  # Use merge patch with rollingUpdate:null to clear the existing rollingUpdate
                  # config, which Kubernetes rejects when strategy type is Recreate.
                  kubectl patch "$kind" "$name" -n "$NAMESPACE" --type=merge -p \
                    '{"spec":{"strategy":{"type":"Recreate","rollingUpdate":null},"template":{"spec":{"priorityClassName":"nightly-gpu-critical"}}}}'
                else
                  kubectl patch "$kind" "$name" -n "$NAMESPACE" --type=strategic -p \
                    '{"spec":{"template":{"spec":{"priorityClassName":"nightly-gpu-critical"}}}}'
                fi
              fi
            done
          done
          # Also patch LeaderWorkerSets if present
          for name in $(kubectl get leaderworkersets -n "$NAMESPACE" -o jsonpath='{.items[*].metadata.name}' 2>/dev/null); do
            echo "  Patching leaderworkerset/$name..."
            kubectl patch leaderworkerset "$name" -n "$NAMESPACE" --type=strategic -p \
              '{"spec":{"leaderWorkerTemplate":{"workerTemplate":{"spec":{"priorityClassName":"nightly-gpu-critical"}}}}}' 2>/dev/null || \
              echo "    Could not patch LWS $name (may not support strategic merge)"
          done
          echo "Priority patching complete"

          # Wait for rolling updates triggered by the priority patch to stabilize.
          # Without this, kubectl wait sees pods from both old and new ReplicaSets,
          # causing "NotFound" errors as old pods are deleted during rollout.
          echo "Waiting for rollouts to stabilize after priority patching..."
          for kind in deployment statefulset; do
            for name in $(kubectl get "$kind" -n "$NAMESPACE" -o jsonpath='{.items[*].metadata.name}' 2>/dev/null); do
              echo "  Waiting for $kind/$name rollout..."
              kubectl rollout status "$kind/$name" -n "$NAMESPACE" --timeout=10m 2>/dev/null || \
                echo "    Rollout status check timed out for $kind/$name (will retry in pod wait)"
            done
          done
          # Also wait for LeaderWorkerSet rollouts, since they were patched above.
          for name in $(kubectl get leaderworkersets -n "$NAMESPACE" -o jsonpath='{.items[*].metadata.name}' 2>/dev/null); do
            echo "  Waiting for leaderworkerset/$name rollout..."
            kubectl rollout status "leaderworkerset/$name" -n "$NAMESPACE" --timeout=10m 2>/dev/null || \
              echo "    Rollout status check failed for leaderworkerset/$name (kubectl may not support rollout for this resource; will rely on pod wait)"
          done
          echo "Rollouts stabilized"

      - name: Show deployment status
        run: |
          echo "=== Deployments ==="
          kubectl get deployments -n "$NAMESPACE" || true
          echo ""
          echo "=== StatefulSets ==="
          kubectl get statefulsets -n "$NAMESPACE" || true
          echo ""
          echo "=== LeaderWorkerSets ==="
          kubectl get leaderworkersets -n "$NAMESPACE" 2>/dev/null || true
          echo ""
          echo "=== Pods ==="
          kubectl get pods -n "$NAMESPACE" -o wide || true
          echo ""
          echo "=== Services ==="
          kubectl get svc -n "$NAMESPACE" || true
          echo ""
          echo "=== Helm releases ==="
          helm list -n "$NAMESPACE" || true
          echo ""
          echo "=== InferencePools ==="
          kubectl get inferencepools -n "$NAMESPACE" || true
          echo ""
          echo "=== HTTPRoutes ==="
          kubectl get httproutes -n "$NAMESPACE" || true
          echo ""
          echo "=== Gateways ==="
          kubectl get gateway -n "$NAMESPACE" || true

      - name: Wait for pods to be ready
        env:
          POD_WAIT_TIMEOUT: ${{ inputs.pod_wait_timeout }}
          POD_READINESS_DELAY: ${{ inputs.pod_readiness_delay }}
        run: |
          echo "Waiting for all pods in $NAMESPACE to be ready (timeout: $POD_WAIT_TIMEOUT)..."
          if ! kubectl wait pod \
            --for=condition=Ready \
            --all \
            -n "$NAMESPACE" \
            --timeout="$POD_WAIT_TIMEOUT"; then
            echo "::error::Pods in $NAMESPACE did not become ready within $POD_WAIT_TIMEOUT"
            echo "--- Pods ---"
            kubectl get pods -n "$NAMESPACE" -o wide || true
            echo "--- Describe non-ready pods ---"
            for pod in $(kubectl get pods -n "$NAMESPACE" --field-selector=status.phase!=Running -o jsonpath='{.items[*].metadata.name}' 2>/dev/null); do
              echo "=== Pod: $pod ==="
              kubectl describe pod "$pod" -n "$NAMESPACE" || true
              kubectl logs "$pod" -n "$NAMESPACE" --tail=50 || true
            done
            exit 1
          fi

          if [ "$POD_READINESS_DELAY" -gt 0 ]; then
            echo "Extra readiness delay: ${POD_READINESS_DELAY}s (model loading)..."
            sleep "$POD_READINESS_DELAY"
          fi

          echo "All pods in $NAMESPACE are ready"
          kubectl get pods -n "$NAMESPACE"

      - name: Wait for gateway to be ready
        run: |
          GATEWAY_NAME=$(kubectl get gateway -n "$NAMESPACE" -o jsonpath='{.items[0].metadata.name}' 2>/dev/null || true)
          if [ -n "$GATEWAY_NAME" ]; then
            echo "Waiting for gateway $GATEWAY_NAME to be programmed..."
            kubectl wait "gateway/$GATEWAY_NAME" \
              --for=condition=Programmed=True \
              -n "$NAMESPACE" \
              --timeout=300s || echo "::warning::Gateway not programmed within timeout"
            kubectl get gateway -n "$NAMESPACE"
          else
            echo "No gateway resource found in $NAMESPACE — skipping wait"
          fi

      - name: Run E2E validation
        run: |
          echo "Running E2E validation for $GUIDE_NAME on GKE..."
          cd .github/scripts/e2e
          ./e2e-validate.sh -n "$NAMESPACE" -v ${{ inputs.e2e_validate_args }}

      - name: Nightly summary
        if: always()
        run: |
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Nightly E2E Results — $GUIDE_NAME (GKE)" >> $GITHUB_STEP_SUMMARY
          echo "| Setting | Value |" >> $GITHUB_STEP_SUMMARY
          echo "|---------|-------|" >> $GITHUB_STEP_SUMMARY
          echo "| Guide | $GUIDE_NAME |" >> $GITHUB_STEP_SUMMARY
          echo "| Platform | GKE ($GKE_CLUSTER_NAME) |" >> $GITHUB_STEP_SUMMARY
          echo "| Namespace | $NAMESPACE |" >> $GITHUB_STEP_SUMMARY
          echo "| Helmfile Env | $HELMFILE_ENV |" >> $GITHUB_STEP_SUMMARY
          echo "| Gateway Type | $GATEWAY_TYPE |" >> $GITHUB_STEP_SUMMARY
          echo "| Accelerator | $ACCELERATOR_TYPE |" >> $GITHUB_STEP_SUMMARY
          echo "| llm-d Ref | ${{ inputs.llm_d_ref }} |" >> $GITHUB_STEP_SUMMARY

      - name: Collect pod logs
        if: always()
        run: |
          mkdir -p /tmp/pod-logs-$GUIDE_NAME
          echo "Collecting pod logs from $NAMESPACE..."
          for pod in $(kubectl get pods -n "$NAMESPACE" --no-headers -o custom-columns=":metadata.name" 2>/dev/null); do
            kubectl logs --all-containers=true -n "$NAMESPACE" "$pod" > "/tmp/pod-logs-$GUIDE_NAME/${pod}.log" 2>&1 || true
            kubectl describe pod -n "$NAMESPACE" "$pod" > "/tmp/pod-logs-$GUIDE_NAME/${pod}-describe.log" 2>&1 || true
          done
          cp /tmp/helmfile-deploy.log "/tmp/pod-logs-$GUIDE_NAME/" 2>/dev/null || true

      - name: Upload pod logs
        uses: actions/upload-artifact@v6
        if: always()
        with:
          name: nightly-pod-logs-${{ inputs.guide_name }}-gke
          path: /tmp/pod-logs-${{ inputs.guide_name }}
          retention-days: 7

      - name: Send Google Chat notification on failure
        if: failure()
        uses: SimonScholz/google-chat-action@3b3519e5102dba8aa5046fd711c4b553586409bb
        with:
          webhookUrl: ${{ secrets.GOOGLE_CHAT_WEBHOOK }}
          jobStatus: ${{ job.status }}
          title: 'Nightly E2E — ${{ inputs.guide_name }} (GKE)'

      - name: Cleanup infrastructure
        if: always() && inputs.skip_cleanup == false
        run: |
          echo "Cleaning up nightly test infrastructure for $GUIDE_NAME..."

          # Destroy helmfile releases
          if [ -f "$GUIDE_PATH/helmfile.yaml.gotmpl" ]; then
            echo "Destroying helmfile releases..."
            cd "$GUIDE_PATH"
            helmfile destroy -e "$HELMFILE_ENV" --namespace "$NAMESPACE" 2>/dev/null || true
            cd "$GITHUB_WORKSPACE"
          fi

          # Delete HTTPRoute
          if [ -n "${{ inputs.httproute_file }}" ] && [ -f "$GUIDE_PATH/${{ inputs.httproute_file }}" ]; then
            kubectl delete -f "$GUIDE_PATH/${{ inputs.httproute_file }}" -n "$NAMESPACE" --ignore-not-found || true
          fi

          # Fallback: uninstall remaining helm releases
          for release in $(helm list -n "$NAMESPACE" -q 2>/dev/null); do
            echo "  Uninstalling release: $release"
            helm uninstall "$release" -n "$NAMESPACE" --ignore-not-found --wait --timeout 60s || true
          done

          # Delete namespace
          echo "Deleting namespace $NAMESPACE..."
          kubectl delete namespace "$NAMESPACE" --ignore-not-found --timeout=120s || true

          echo "Nightly cleanup complete"

      - name: Uncordon nodes cordoned by this run
        if: always()
        run: |
          if [ -n "$NIGHTLY_CORDONED_NODES" ]; then
            echo "Uncordoning nodes that were cordoned by this nightly run..."
            for node in $NIGHTLY_CORDONED_NODES; do
              echo "  Uncordoning $node"
              kubectl uncordon "$node" 2>/dev/null || true
            done
          fi
